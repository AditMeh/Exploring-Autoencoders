# Exploring-Autoencoders
Learning about auto encoders and latent spaces


Experiments TODO:
 
 Standard autoencoder on MNIST:
  - Sparse autoencoders:
    - Identity function:
    - Noisy inputs to sparse autoencoder (robustness to noise, resulting in a richer latent space)
    - Image denoising
    - Losses to try:
      - L1 regularized
      - KL divergence regularization
 
Perhaps: 
  - Visulization of activations
  - VAE on MNIST (if I have time)
  - Comparison of PCA vs Overcomplete autoencoder (compare latent space vs PCA)
  - Experiment with the trivial autoencoder for the identity mapping case (photometric loss, L = ||x - net(x)||^2)



(TODO) List of resources used partitioned by category. For later reference. 
