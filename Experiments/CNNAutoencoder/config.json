{
    "training_params": {
        "batch_size": 32,
        "epochs": 100,
        "lr": 0.001
    },
    "architecture_params": {
        "sizes": [3, 8, 32, 64, 128],
        "h": 32,
        "w": 32,
        "num_dense_layers": 2,
        "fcnn": false

    },
    "dataset_params": {
        "name": "cifar",
        "hyperparams": {
            "batch_size" : 32,
            "classes": ["frog"]
        }
    }
}